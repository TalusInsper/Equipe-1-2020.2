{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução \n",
    "Kannada é um língua falada predominantemente pelo povo de Karnataka, localizada na região sudoeste da Índia. Essa língua possui aproximandente 45 milhões de praticantes.\n",
    "\n",
    "O objetivo desse projeto é construir uma Rede Neural Convulucional (CNN) que consiga interpretar a escrita kannadense a partir de um banco de dados, onde há mais de 60.000 imagens de 0 a 9, escritos a mão, em kannadense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando datasets em dataframes\n",
    "train = pd.read_csv('Kannada-MNIST/train.csv')\n",
    "test = pd.read_csv('Kannada-MNIST/test.csv')\n",
    "dig = pd.read_csv('Kannada-MNIST/Dig-MNIST.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Conhecendo os dados \n",
    "\n",
    "Cada imagem possui 28 pixels em altura e 28 em comprimento, o que totaliza 784 pixels por imagem (28x28). Cada pixel tem o seu próprio valor associado, o que indica o tom claro e escuro do respectivo pixel.\n",
    "\n",
    "Para podermos observar melhor essas imagens e como elas se comportam, realizaremos uma análise desses dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando o tamanho do nosso dataframe \n",
    "print('O dataframe de TREINO possui {} LINHAS e {} COLUNAS'.format(train.shape[0], train.shape[1]))\n",
    "print('O dataframe de TESTE possui {} LINHAS e {} COLUNAS'.format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(train.label.value_counts().index, train.label.value_counts())\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Número de imagens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui plotamos um gráfico de barra para entendermos como está a distribuição das imagens. No nosso dataset, podemos observar que o número de imagens está uniformemente distribuido, o que nos leva a não precisar realizar algum tratamento ou manipulação em relação à quantidade para cada label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada label, temos 6.000 imagens, o que é um bom número para se trabalhar. \n",
    "\n",
    "Em seguida, vamos plotar uma das imagens. Como os pixels estão distribuídos em 784 colunas, precisamos reagrupá-las de forma que estajam no formato 28x28. Por isso utilizaremos o reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 8\n",
    "number = train.iloc[num,1:].values.reshape(28,28)\n",
    "plt.imshow(number, cmap=plt.get_cmap('gray'))\n",
    "plt.title('Imagem do número {} em Kannada'.format(str(num)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos uma boa noção sobre o dataset que estamos trabalhando! Agora iniciaremos o processo de montagem do nosso CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Pré-processamento dos dados \n",
    "\n",
    "Para podermos utlizar as imagens como inputs no CNN, precisamos realizar alguns processamentos.\n",
    "\n",
    "Iniciaremos com uma separação do nosso target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando feature e targets \n",
    "X_train=train.drop('label',axis=1)\n",
    "Y_train=train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para podermos acelerar o processo de treinamento do nosso modelo, realizaremos uma normalização. Em outras palavras, já que os valores do pixel variam entre 0 e 255, dividiremos todos os valores por 255, desse modo, os inputs terão valores \"leves\" para serem trabalhadas no CNN. No final, os valores do pixels vão variar entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "test = test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também, passaremos as variáveis dos labels de numéricas para categóricas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos prestes a montar o nosso CNN. O passo final antes de iniciar a montagem seria separar o nosso train com o auxilio do sklearn.\n",
    "\n",
    "Decidimos utilizar a proporção de 70% e 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E mais um detalhe imporante!\n",
    "\n",
    "Como dito antes, os pixels estão distribuídas de forma linear em 784 colunas, então precisamos agrupá-los no formato 28x28x1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values.reshape(-1,28,28,1) \n",
    "x_val = x_val.values.reshape(-1,28,28,1)\n",
    "test = test.iloc[:, 1:].values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Modelo \n",
    "\n",
    "Aqui se encontra uma breve explicação sobre CNN e algumas definições importantes: https://medium.com/data-hackers/uma-introdu%C3%A7%C3%A3o-as-redes-neurais-convolucionais-utilizando-o-keras-41ee8dcc033e\n",
    "\n",
    "Agora iniciaremos a montagem do modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importantando bibliotecas \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo inicial\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(filters = 32,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (28,28,1)))\n",
    "\n",
    "model_1.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Conv2D(filters = 64,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model_1.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "model_1.add(Conv2D(filters = 128,\n",
    "                 kernel_size = (3,3),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "\n",
    "model_1.add(Dense(256, activation = \"relu\"))\n",
    "\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizadores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer = 'adam', loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando primeira performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_1.fit(datagen.flow(x_train, y_train, batch_size = batch_size,), \n",
    "                      epochs = epochs,\n",
    "                      validation_data = (x_val, y_val), \n",
    "                      validation_steps = 50,\n",
    "                      steps_per_epoch = x_train.shape[0] // batch_size,\n",
    "                      callbacks = [learning_rate_reduction, es])\n",
    "\n",
    "# Resultado da primeira iteração\n",
    "fig,ax=plt.subplots(2,1)\n",
    "fig.set\n",
    "x=range(1,1+epochs)\n",
    "ax[0].plot(x,history.history['loss'],color='red')\n",
    "ax[0].plot(x,history.history['val_loss'],color='blue')\n",
    "\n",
    "ax[1].plot(x,history.history['accuracy'],color='red')\n",
    "ax[1].plot(x,history.history['val_accuracy'],color='blue')\n",
    "ax[0].legend(['trainng loss','validation loss'])\n",
    "ax[1].legend(['trainng acc','validation acc'])\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(x_val, y_val, verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model_1.predict(x_val)\n",
    "y_grand_truth = y_val\n",
    "\n",
    "y_predicted = np.argmax(y_predicted,axis=1)\n",
    "y_grand_truth = np.argmax(y_grand_truth,axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_grand_truth, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm,fmt=\".0f\", annot=True, linewidths=0.1)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Grand Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação em cima de dados extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_extra = train.drop('label',axis=1)\n",
    "y_extra = train.label\n",
    "\n",
    "x_extra = x_extra/255\n",
    "\n",
    "x_extra = x_extra.values.reshape(-1,28,28,1) \n",
    "y_extra = to_categorical(y_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_extra = model_1.predict(x_extra)\n",
    "y_grand_truth_extra = y_extra\n",
    "\n",
    "y_predicted_extra = np.argmax(y_predicted_extra, axis=1)\n",
    "y_grand_truth_extra = np.argmax(y_grand_truth,axis=1)\n",
    "\n",
    "cm_extra = confusion_matrix(y_grand_truth_extra, y_predicted_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm_extra,fmt=\".0f\", annot=True, linewidths=0.1)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Grand Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
